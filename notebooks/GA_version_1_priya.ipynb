{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "import re\n",
    "from pandas import json_normalize\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('data_given/train.csv')\n",
    "test_df=pd.read_csv('data_given/test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Stages of Data Preprocessing and Data transformation ##\n",
    "\n",
    "\n",
    "#1.Function for extracting features from date column\n",
    "\n",
    "def date_process(df):\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y%m%d\") # seting the column as pandas datetime\n",
    "    df[\"weekday\"] = df['date'].dt.weekday #extracting week day\n",
    "    df[\"day\"] = df['date'].dt.day # extracting day\n",
    "    df[\"month\"] = df['date'].dt.month # extracting month\n",
    "    df[\"year\"] = df['date'].dt.year # extracting year\n",
    "    df['visitHour'] = (df['visitStartTime'].apply(lambda x: str(datetime.fromtimestamp(x).hour))).astype(int)\n",
    "    \n",
    "    return df\n",
    "train_df=date_process(train_df)\n",
    "test_df=date_process(test_df)\n",
    "\n",
    "#2.Function to validate the json columns in the dataset    \n",
    "def column_validator(df):\n",
    "    cols=[]\n",
    "    for col in df.columns:\n",
    "        if( type(df[col].values[0]) == str ):\n",
    "            txt = df[col].values[0]\n",
    "            if re.search(\"^{.*}$\",txt):\n",
    "                cols.append(col)\n",
    "    return cols  # Returns the json columns\n",
    "\n",
    "#2.1 Function for flattening the json columns and merge them with original dataset\n",
    "def json_to_df(df,json_columns):\n",
    "    for column in json_columns:\n",
    "        column_to_df= json_normalize([json.loads(x) for x in df[column]])\n",
    "        df= df.drop(column, axis=1).merge(column_to_df, right_index=True, left_index=True) # drop the flattened column from the original dataset\n",
    "    return df ## returns new dataframe with flattened json columns\n",
    "\n",
    "\n",
    "train_json_columns = column_validator(train_df)\n",
    "test_json_columns = column_validator(test_df)\n",
    "\n",
    "if train_json_columns is not None:\n",
    "    train_df=json_to_df(train_df,train_json_columns)\n",
    "    \n",
    "if test_json_columns is not None:    \n",
    "    test_df=json_to_df(test_df,test_json_columns)\n",
    "\n",
    "\n",
    "#3.Dropping columns which have more than 50% of null values and not contributing to the target variable\n",
    "\n",
    "def remove_nan_cols(df)\n",
    "    for col in df.columns:\n",
    "        if (df[col].isnull().sum() >  (0.5 * len(df))):\n",
    "            df.drop(col,axis=1,inplace=True)\n",
    "    return None\n",
    "remove_nan_cols(train_df)\n",
    "remove_nan_cols(test_df)\n",
    " \n",
    "\n",
    "#4.Imputation of null values \n",
    "def impute_na(df):\n",
    "    for col in df.columns:\n",
    "        df[col].fillna(0.inplace=True)\n",
    "    return None\n",
    "\n",
    "impute_na(train_df)\n",
    "impute_na(test_df)\n",
    "\n",
    "train_df['adwordsClickInfo.isVideoAd'].fillna(True, inplace=True) # filling boolean with True\n",
    "train_df[train_df['city'] == \"(not set)\"]['city'] = np.nan\n",
    "train_df['city'].fillna(\"NaN\", inplace=True)\n",
    "    \n",
    "\n",
    "test_df['isTrueDirect'].fillna(False, inplace=True) \n",
    "test_df['adwordsClickInfo.isVideoAd'].fillna(True, inplace=True) # filling boolean with True\n",
    "test_df[test_df['city'] == \"(not set)\"]['city'] = np.nan\n",
    "test_df['city'].fillna(\"NaN\", inplace=True)   \n",
    "\n",
    "#5.Changing datatypes from object to desired ones\n",
    "def data_type_convert(df):\n",
    "    for col in df.columns:\n",
    "        if ( type(df[col][0]) == str and df[col][0].isdigit() ):\n",
    "            print(col)\n",
    "            df[col]=df[col].astype(int)\n",
    "\n",
    "data_type_convert(train_df)\n",
    "data_type_convert(test_df)\n",
    "\n",
    "#6. Removing columns with constant values or with zero standard deviation\n",
    "def remove_zero_std_cols(df):\n",
    "    for column in df.columns:\n",
    "        if (df[column].nunique()==1):\n",
    "            df.drop(column,axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df=remove_zero_std_cols(train_df)\n",
    "test_df=remove_zero_std_cols(test_df)\n",
    "\n",
    "\n",
    "#7. sessionId col is removed as it is unique id and does'nt contribute to the target variable\n",
    "train_df.drop('sessionId',axis=1,inplace=True)\n",
    "test_df.drop('sessionId',axis=1,inplace=True)\n",
    "train_df.drop('visitStartTime',axis=1,inplace=True) #removing visitStartime as it was extraced into visitHour\n",
    "test_df.drop('visitStartTime',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#8 Function to gather categorical columns in the dataset\n",
    "def categorical_cols(df):\n",
    "    cat_cols=[]\n",
    "    for col in df.columns:\n",
    "        if (type(df[col][0]) == str or type(df[col][0]) == np.bool_) :\n",
    "            cat_cols.append(col)\n",
    "    return cat_cols # returns categorical columns in the dataset\n",
    "    \n",
    "train_cat_cols=categorical_cols(train_df)   # collecting all categorical columns in the train dataset \n",
    "test_cat_cols=categorical_cols(test_df)     # collecting all categorical columns in the test dataset\n",
    "\n",
    "#8.1 Function for encoding categorical values to numerical values\n",
    "\n",
    "def label_encoding(cat_cols,df):\n",
    "    # creating instance of labelencoder\n",
    "    labelencoder = LabelEncoder()\n",
    "    # Assigning numerical values and storing in same column\n",
    "    for column in cat_cols:\n",
    "        df[column] = labelencoder.fit_transform(df[column].astype(str))\n",
    "    return df\n",
    "\n",
    "label_encoding(train_cat_cols,train_df)\n",
    "label_encoding(test_cat_cols,test_df) \n",
    "\n",
    "#9. Imputing pageviews column with KNNImputer in both train and test data\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer=KNNImputer()\n",
    "\n",
    "imputer_train_df=imputer.fit_transform(train_df[['pageviews']]) ## Imputing pageviews with KNNimputer in training data\n",
    "train_df['pageviews']=imputer_train_df\n",
    "\n",
    "imputer_test_df=imputer.fit_transform(test_df[['pageviews']]) ## imputing pageviews with KNNimputer in test data\n",
    "test_df['pageviews']=imputer_test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Model Training begins here \n",
    "\n",
    "import datetime\n",
    "\n",
    "X = train_df[train_df['date']<=datetime.date(2017,5,31)] ## train data for the months till May 31 2017\n",
    "val_X = train_df[train_df['date']>datetime.date(2017,5,31)] ## validation data for the months of june 2017 and july 2017\n",
    "\n",
    "X = X.drop(['date'], axis = 1)\n",
    "val_X = train_df.drop(['date'], axis = 1)\n",
    "\n",
    "y = np.log1p(X[\"transactionRevenue\"].values)\n",
    "val_y = np.log1p(val_X[\"transactionRevenue\"].values)\n",
    "y = pd.DataFrame(y)\n",
    "val_y = pd.DataFrame(val_y)\n",
    "x = X.drop(['transactionRevenue'], axis = 1)\n",
    "val_x = val_X.drop(['transactionRevenue'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import xgboost as xg \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = xg.XGBRegressor(objective ='reg:squarederror', n_estimators = 1000, verbosity=1,learning_rate=0.5,max_depth=8)\n",
    "model.fit(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Metrics \n",
    "model.score(x,y)\n",
    "y_train_predict = model.predict(x)\n",
    "rmse = (np.sqrt(MSE(y, y_train_predict)))\n",
    "r2 = r2_score(y, y_train_predict)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "\n",
    "y_test_predict = model.predict(val_x)\n",
    "# root mean square error of the model\n",
    "rmse = (np.sqrt(MSE(val_y, y_test_predict)))\n",
    "\n",
    "# r-squared score of the model\n",
    "r2 = r2_score(val_y, y_test_predict)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. Creating Pickle file and generating the output with pickle file\n",
    "import pickle\n",
    "filename = 'xgboost_model.pickle'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "pred_transaction_rev=loaded_model.predict(test_df) # Predicting with Test data\n",
    "output_df=pd.DataFrame(pred_transaction_rev) # converting predicted values into Dataframe \n",
    "output_df.to_csv('predicted_file.csv') # Saving the predicted values into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
